{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CherylRuo/Documents/anaconda/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import svm, tree, preprocessing\n",
    "from IPython.display import Image \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.ensemble\n",
    "import pydotplus\n",
    "%pylab inline\n",
    "fileURL ='car.data.txt'\n",
    "data = pd.read_csv(fileURL, names=['buying','maint','doors','persons','lug_boot','safety','acceptability'], header=None, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* features:\n",
      "Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lex = preprocessing.LabelEncoder()\n",
    "w = data.ix[:,0:6].as_matrix()\n",
    "nw = lex.fit_transform(w[0])\n",
    "for i in w[1:]:\n",
    "    nw = np.vstack([nw, lex.fit_transform(i)])\n",
    "transformed_data = pd.DataFrame(nw, columns=data.columns[0:6])\n",
    "features = transformed_data.columns\n",
    "print(\"* features:\", features, sep=\"\\n\")\n",
    "ley = preprocessing.LabelEncoder()\n",
    "Y = data['acceptability'].as_matrix()\n",
    "Y = ley.fit_transform(Y)\n",
    "X = transformed_data[features]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ley = preprocessing.LabelEncoder()\n",
    "Y = data['acceptability'].as_matrix()\n",
    "Y = ley.fit_transform(Y)\n",
    "X = transformed_data[features]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91954023,  0.91954023,  0.91954023,  0.91954023,  0.9244186 ,\n",
       "        0.9244186 ,  0.9244186 ,  0.9244186 ,  0.9244186 ,  0.9244186 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_result = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy = 0.92119089317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = metrics.accuracy_score(Y_test, clf.predict(X_test))\n",
    "print ('SVM Accuracy = %s' % (score))\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Support Vector Machines Classifier\n",
    "Mean value: 0.92247\n",
    "Standard Deviation: 0.00239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn AdaBoost Accuracy = 0.922942206655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.91954023,  0.92528736,  0.92528736,  0.92528736,  0.90116279,\n",
       "        0.93023256,  0.9127907 ,  0.91860465,  0.9244186 ,  0.91860465])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost\n",
    "clf1 = sklearn.ensemble.AdaBoostClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf1.predict(X_test))\n",
    "print ('sklearn AdaBoost Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf1, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Ada Boost Classifier\n",
    "Mean value: 0.92012\n",
    "Standard Deviation: 0.00787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Bagging Accuracy = 0.92819614711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.92528736,  0.94827586,  0.91954023,  0.86781609,  0.91860465,\n",
       "        0.95348837,  0.87209302,  0.8255814 ,  0.90697674,  0.89534884])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "clf2 = sklearn.ensemble.BaggingClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf2.predict(X_test))\n",
    "print ('sklearn Bagging Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf2, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Bagging Classifier\n",
    "Mean value: 0.901\n",
    "Standard Deviation: 0.04163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy = 0.92819614711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.92528736,  0.94827586,  0.91954023,  0.86781609,  0.91860465,\n",
       "        0.95348837,  0.86046512,  0.8372093 ,  0.91860465,  0.89534884])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "clf3 = sklearn.ensemble.RandomForestClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf3.predict(X_test))\n",
    "print ('sklearn Random Forest Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf3, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Random Forest Classifier\n",
    "Mean value: 0.89753\n",
    "Standard Deviation: 0.0423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy = 0.935201401051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.92528736,  0.94827586,  0.94252874,  0.86781609,  0.90697674,\n",
       "        0.95348837,  0.88372093,  0.86046512,  0.93023256,  0.89534884])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra Trees\n",
    "clf4 = sklearn.ensemble.ExtraTreesClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf4.predict(X_test))\n",
    "print ('sklearn Random Forest Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf4, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Extra Trees Classifier\n",
    "Mean value: 0.91141\n",
    "Standard Deviation: 0.03191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Stacking Accuracy = 0.935201401051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.92528736,  0.94827586,  0.91954023,  0.86781609,  0.91860465,\n",
       "        0.95348837,  0.86046512,  0.86046512,  0.93023256,  0.89534884])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
    "                          meta_classifier=lr).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, sclf.predict(X_test))\n",
    "print ('sklearn Stacking Accuracy = %s' % (score))\n",
    "scores = cross_val_score(sclf, X, Y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of Stacking Classifier\n",
    "Mean value: 0.90211\n",
    "Standard Deviation: 0.04272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Write one brief paragraph describing the dataset you chose. \n",
    "Answer: \n",
    "I am using car Evaluation dataset which use serveral car features to evaluate if people accept car\n",
    "Attributes for car.data :\n",
    "   buying       v-high, high, med, low\n",
    "   maint        v-high, high, med, low\n",
    "   doors        2, 3, 4, 5-more\n",
    "   persons      2, 4, more\n",
    "   lug_boot     small, med, big\n",
    "   safety       low, med, high\n",
    " The number of total instances is 1728. \n",
    "\n",
    "\n",
    "2.Applying 10-fold cross validation and at least 3 metrics of your choice, evaluate how multiple classification methods perform on that task. You must use at least 1 simple classifier (for comparison), and all ensemble methods discussed in this module. Bagging, Ada Boost, Random Forests and Extra Trees are natively implemented in scikit learn. For stacking, you can use the implementation available through the Machine Learning Extensions package (http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/). I will also provide an implementation, but the former is likely more up-to-date. \n",
    "\n",
    "\n",
    "3.Lastly, provide a brief write up describing which model yielded the best performance and why you think that was the case. \n",
    "Answer: \n",
    "The simple classifier I use is Support Vector Machines. I computed both means value and SD values of each classifier scores. But it seems neither of them is good for evaluating the comparison. I also computed accuarcy of each classifiers. These are listed above and below each function. Depend on that, the best one is stacking. It has the highest accuracy of 0.938704028021. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
