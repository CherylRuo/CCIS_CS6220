{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CherylRuo/Documents/anaconda/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import svm, tree, preprocessing\n",
    "from IPython.display import Image \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.ensemble\n",
    "import pydotplus\n",
    "%pylab inline\n",
    "fileURL ='car.data.txt'\n",
    "data = pd.read_csv(fileURL, names=['buying','maint','doors','persons','lug_boot','safety','acceptability'], header=None, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* features:\n",
      "Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lex = preprocessing.LabelEncoder()\n",
    "w = data.ix[:,0:6].as_matrix()\n",
    "nw = lex.fit_transform(w[0])\n",
    "for i in w[1:]:\n",
    "    nw = np.vstack([nw, lex.fit_transform(i)])\n",
    "transformed_data = pd.DataFrame(nw, columns=data.columns[0:6])\n",
    "features = transformed_data.columns\n",
    "print(\"* features:\", features, sep=\"\\n\")\n",
    "ley = preprocessing.LabelEncoder()\n",
    "Y = data['acceptability'].as_matrix()\n",
    "Y = ley.fit_transform(Y)\n",
    "X = transformed_data[features]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ley = preprocessing.LabelEncoder()\n",
    "Y = data['acceptability'].as_matrix()\n",
    "Y = ley.fit_transform(Y)\n",
    "X = transformed_data[features]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: \n",
      "[ 0.91954023  0.91954023  0.91954023  0.91954023  0.9244186   0.9244186\n",
      "  0.9244186   0.9244186   0.9244186   0.9244186 ]\n",
      "SVM Accuracy = 0.92119089317\n",
      "tn=526 fp=0 fn=45 tp=0\n",
      "Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       526\n",
      "          1       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.85      0.92      0.88       571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CherylRuo/Documents/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, Y_train)\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "score = metrics.accuracy_score(Y_test, clf.predict(X_test))\n",
    "print ('SVM Accuracy = %s' % (score))\n",
    "print\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, clf.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, clf.predict(X_test))\n",
    "print ('Classification report: ')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn AdaBoost Accuracy = 0.922942206655\n",
      "Cross validation score: \n",
      "[ 0.91954023  0.92528736  0.92528736  0.92528736  0.90116279  0.93023256\n",
      "  0.9127907   0.91860465  0.9244186   0.91860465]\n",
      "tn=526 fp=0 fn=44 tp=1\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       526\n",
      "          1       1.00      0.02      0.04        45\n",
      "\n",
      "avg / total       0.93      0.92      0.89       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ada Boost\n",
    "clf1 = sklearn.ensemble.AdaBoostClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf1.predict(X_test))\n",
    "print ('sklearn AdaBoost Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf1, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, clf1.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, clf1.predict(X_test))\n",
    "print ('Classification report')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Bagging Accuracy = 0.938704028021\n",
      "Cross validation score: \n",
      "[ 0.92528736  0.94827586  0.91954023  0.85632184  0.91860465  0.95348837\n",
      "  0.8372093   0.86046512  0.93023256  0.89534884]\n",
      "tn=518 fp=8 fn=27 tp=18\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       526\n",
      "          1       0.69      0.40      0.51        45\n",
      "\n",
      "avg / total       0.93      0.94      0.93       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "clf2 = sklearn.ensemble.BaggingClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf2.predict(X_test))\n",
    "print ('sklearn Bagging Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf2, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, clf2.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, clf2.predict(X_test))\n",
    "print ('Classification report')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy = 0.935201401051\n",
      "Cross validation score: \n",
      "[ 0.92528736  0.94827586  0.91954023  0.86781609  0.91860465  0.95348837\n",
      "  0.84883721  0.80232558  0.91860465  0.89534884]\n",
      "tn=518 fp=8 fn=29 tp=16\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       526\n",
      "          1       0.67      0.36      0.46        45\n",
      "\n",
      "avg / total       0.92      0.94      0.93       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "clf3 = sklearn.ensemble.RandomForestClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf3.predict(X_test))\n",
    "print ('sklearn Random Forest Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf3, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, clf3.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, clf3.predict(X_test))\n",
    "print ('Classification report')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy = 0.935201401051\n",
      "Cross validation score: \n",
      "[ 0.92528736  0.94827586  0.94252874  0.86781609  0.90697674  0.95348837\n",
      "  0.88372093  0.86046512  0.93023256  0.89534884]\n",
      "tn=518 fp=8 fn=29 tp=16\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       526\n",
      "          1       0.67      0.36      0.46        45\n",
      "\n",
      "avg / total       0.92      0.94      0.93       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees\n",
    "clf4 = sklearn.ensemble.ExtraTreesClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, clf4.predict(X_test))\n",
    "print ('sklearn Random Forest Accuracy = %s' % (score))\n",
    "scores = cross_val_score(clf4, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, clf4.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, clf4.predict(X_test))\n",
    "print ('Classification report')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Stacking Accuracy = 0.92819614711\n",
      "Cross validation score: \n",
      "[ 0.90229885  0.94827586  0.91954023  0.86781609  0.90697674  0.95348837\n",
      "  0.88372093  0.86046512  0.93023256  0.89534884]\n",
      "tn=513 fp=13 fn=28 tp=17\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       526\n",
      "          1       0.57      0.38      0.45        45\n",
      "\n",
      "avg / total       0.92      0.93      0.92       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
    "                          meta_classifier=lr).fit(X_train, Y_train)\n",
    "score = metrics.accuracy_score(Y_test, sclf.predict(X_test))\n",
    "print ('sklearn Stacking Accuracy = %s' % (score))\n",
    "scores = cross_val_score(sclf, X, Y, cv=10)\n",
    "print ('Cross validation score: ')\n",
    "print (scores)\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test, sclf.predict(X_test)).ravel()\n",
    "print ('tn=%s'%(tn), 'fp=%s'%(fp), 'fn=%s'%(fn), 'tp=%s'%(tp))\n",
    "classification_report = metrics.classification_report(Y_test, sclf.predict(X_test))\n",
    "print ('Classification report')\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "I am using car Evaluation dataset which use serveral car features to evaluate if people accept car\n",
    "Attributes for car.data :\n",
    "   buying       v-high, high, med, low\n",
    "   maint        v-high, high, med, low\n",
    "   doors        2, 3, 4, 5-more\n",
    "   persons      2, 4, more\n",
    "   lug_boot     small, med, big\n",
    "   safety       low, med, high\n",
    " The number of total instances is 1728. \n",
    " This is with binary class. \n",
    " The original classes are:\n",
    " \n",
    "  class      N          N[%]\n",
    "   -----------------------------\n",
    "   unacc     1210     (70.023 %) \n",
    "   acc        384     (22.222 %) \n",
    "   good        69     ( 3.993 %) \n",
    "   v-good      65     ( 3.762 %) \n",
    "   \n",
    " I generate unacc and acc, which is has accident history or not to binary class as 0, \n",
    " and good and v-good, which is in good or very good condition as 1.\n",
    "\n",
    "3.\n",
    "The simple classifier I use is Support Vector Machines. \n",
    "I computed both mean values and SD values of each one's cross validation scores. \n",
    "Description of Support Vector Machines Classifier Mean value: 0.92247 Standard Deviation: 0.00239\n",
    "Description of Ada Boost Classifier Mean value: 0.92012 Standard Deviation: 0.00787\n",
    "Description of Bagging Classifier Mean value: 0.901 Standard Deviation: 0.04163\n",
    "Description of Random Forest Classifier Mean value: 0.89753 Standard Deviation: 0.0423\n",
    "Description of Extra Trees Classifier Mean value: 0.91141 Standard Deviation: 0.03191\n",
    "Description of Stacking Classifier Mean value: 0.90211 Standard Deviation: 0.04272\n",
    "According to these results, we can see that Support Vector Machines Classifier has highest mean value\n",
    "and lowest SD value. So it is most accurate and most stable.\n",
    "According to classification report, SVM is still good but not the best.\n",
    "In my opinion, cross validation scores is best to decribe a classifier. Because if a classifier is more\n",
    "accurate and more stable, it could fit most data. Maybe specific classifier is good for specific data.\n",
    "Generally, a classifier that is good enough for most data should be the best."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
